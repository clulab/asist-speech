#!/usr/bin/env python

"""Agent that can process one or more audio streams and outputs messages
corresponding to real-time ASR transcriptions.

Example usage:
    ./tomcat_asr_agent

To see all available options, run:
    ./tomcat_asr_agent -h
"""


import os
import sys
import time
import asyncio
import logging
import datetime
import threading
from uuid import uuid4
from logging import debug, info
from urllib.parse import urlparse, parse_qs
from utils import float32_array_to_int16_array
from audio_stream import AudioStream
from google_asr_client import GoogleASRClient


# This mutable global variable should be encapsulated in a class in the future.
# It can be set by listening for a message on the message bus, in order to
# synchronize recording start and stop timestamps.
RECORDING_IN_PROGRESS = True


async def message_handler(
    websocket,
    path,
    use_mqtt: bool = False,
    mqtt_host: str = "localhost",
    mqtt_port: int = 1883,
):
    query_params = parse_qs(urlparse(websocket.path).query)

    participant_id = query_params["id"][0]
    if participant_id == "null":
        participant_id = str(uuid4())
    sample_rate = int(query_params["sampleRate"][0])

    await websocket.send(participant_id)

    info(f"Participant {participant_id} is now connected.")

    # Start the audio stream and ASR client.
    audio_stream = AudioStream()
    asr_client = GoogleASRClient(
        audio_stream,
        sample_rate,
        participant_id=participant_id,
        use_mqtt=use_mqtt,
        mqtt_host=mqtt_host,
        mqtt_port=mqtt_port,
    )
    threading.Thread(target=asr_client.run).start()

    with open(f"participant_{participant_id}.raw", "wb") as f:
        async for data in websocket:
            debug(
                f"Received chunk of size {len(data)} bytes from browser at "
                f"{datetime.datetime.utcnow().isoformat()}Z"
            )
            if RECORDING_IN_PROGRESS:
                f.write(data)

            chunk = float32_array_to_int16_array(data)
            audio_stream.fill_buffer(chunk)


if __name__ == "__main__":
    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter

    parser = ArgumentParser(
        description="ToMCAT ASR Agent",
        formatter_class=ArgumentDefaultsHelpFormatter,
    )

    parent_parser = ArgumentParser(add_help=False)
    mqtt_options = parent_parser.add_argument_group("MQTT-related options")
    mqtt_options.add_argument(
        "--use_mqtt",
        action="store_true",
        help=(
            "Publish messages to an MQTT message broker instead of printing "
            "to standard output."
        ),
    )

    mqtt_options.add_argument(
        "--mqtt_host",
        type=str,
        default="localhost",
        help="Host that the MQTT broker is running on.",
    )

    mqtt_options.add_argument(
        "--mqtt_port",
        type=int,
        default=1883,
        help="Port that the MQTT broker is running on.",
    )

    mqtt_options.add_argument(
        "--publish_topic",
        type=str,
        help="Message bus topic to publish to.",
        default="agents/asr_agent",
    )

    # ==========================================
    # Adding subparsers for the different modes.
    # ==========================================

    subparsers = parser.add_subparsers(dest="mode", required=True)

    parser_stdin = subparsers.add_parser(
        "stdin",
        help=(
            "Run the agent in stdin mode, allowing it to process raw audio "
            "from standard input."
        ),
        formatter_class=ArgumentDefaultsHelpFormatter,
        parents=[parent_parser],
    )

    parser_stdin.add_argument(
        "sample_rate",
        type=int,
        default=44100,
        help="Sample rate in Hertz of the raw input audio stream.",
        nargs="?",
    )

    parser_stdin.add_argument(
        "chunk_size",
        type=int,
        default=3200,
        help=(
            "Number of bytes to read at a time from the input audio stream."
        ),
        nargs="?",
    )

    parser_microphone = subparsers.add_parser(
        "microphone",
        help="Run the agent using your computer's microphone.",
        formatter_class=ArgumentDefaultsHelpFormatter,
        parents=[parent_parser],
    )

    parser_microphone.add_argument(
        "--engine",
        type=str,
        help="ASR engine to use",
        choices=("google", "pocketsphinx"),
        default="google",
    )

    parser_microphone.add_argument(
        "--sample_rate",
        type=int,
        default=44100,
        help="Sample rate in Hertz to use for microphone recording.",
    )

    parser_websockets = subparsers.add_parser(
        "websockets",
        help=(
            "Run the agent in websockets mode, allowing it to act as a "
            "server that can process multiple audio streams simultaneously."
        ),
        formatter_class=ArgumentDefaultsHelpFormatter,
        parents=[parent_parser],
    )

    parser_websockets.add_argument(
        "--ws_host",
        type=str,
        default="localhost",
        help="Host to run the websocket server on.",
    )

    parser_websockets.add_argument(
        "--ws_port",
        type=int,
        default=8888,
        help="Port to run the websocket server on.",
    )

    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO)

    try:
        if args.mode == "stdin":
            audio_stream = AudioStream()
            asr_client = GoogleASRClient(
                audio_stream,
                args.sample_rate,
                args.chunk_size,
                use_mqtt=args.use_mqtt,
                mqtt_host=args.mqtt_host,
                mqtt_port=args.mqtt_port,
            )
            asr_thread = threading.Thread(target=asr_client.run, daemon=True)
            asr_thread.start()

            while True:
                data = sys.stdin.buffer.read(args.chunk_size)
                if not data:
                    time.sleep(1)
                    audio_stream.closed = True
                    asr_thread.join(timeout=1)
                    break
                else:
                    chunk = float32_array_to_int16_array(data)
                    audio_stream.fill_buffer(chunk)

        elif args.mode == "microphone":
            if args.engine == "google":
                from microphone_stream import MicrophoneStream

                audio_stream = MicrophoneStream(args.sample_rate)

                with audio_stream as stream:
                    asr_client = GoogleASRClient(
                        stream,
                        args.sample_rate,
                        use_mqtt=args.use_mqtt,
                        mqtt_host=args.mqtt_host,
                        mqtt_port=args.mqtt_port,
                    )
                    asr_client.run()
            else:
                from pocketsphinx_asr_client import PocketSphinxASRClient

                asr_client = PocketSphinxASRClient(
                    args.sample_rate, round(args.sample_rate / 10)
                )
                asr_client.run()

        else:
            import websockets
            from functools import partial

            asyncio.gather(
                websockets.serve(
                    partial(
                        message_handler,
                        use_mqtt=args.use_mqtt,
                        mqtt_host=args.mqtt_host,
                        mqtt_port=args.mqtt_port,
                    ),
                    args.ws_host,
                    args.ws_port,
                ),
            )
            asyncio.get_event_loop().run_forever()
    except KeyboardInterrupt:
        sys.stderr.write("Keyboard interrupt (Ctrl-C) detected. Exiting now.")
